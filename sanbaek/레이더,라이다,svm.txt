레이더 Radar
	RAdio
	Detection
	And
	Ranging
	레이더 정리
	레이더 필기정리
	
	무선 전자기파를 이용해 물체를 탐지하고 거리를 측정하는 기술
	사용 전자기 스펙트럼 - 무선전파
		송신 안테나를 통해 특정 주파수 대역을 방사하고,
		주변 물체에 반사되어 돌아오는 신호를 수신
		결과적으로, 거리/물체의 존재 유무/속도를 산출
	
	{시간 지연, 도플러 효과}를 분석하여 목표물까지의 거리와 상대 속도를 파악
	
	사용 주파수 대역
		24 GHz 또는 77 GHz
	레이더 파장 범위
		수십 센티미터에서 수 밀리미터 수준
		예: 30cm ~ 3mm
		
		비/눈/안개/먼지의 영향에서 비교적 자유로움
			이 입자는 보통 수십~수백 마이크로미터(μm) 정도 크기인데,
			레이더 전파는 이보다 훨씬 긴 파장을 가지므로
			입자에 의한 산란scattering과 흡수absorption의 영향을 덜 받음
		
		라이다에 비해 파장이 비교적 길기 때문에
			공간 해상도spatial resolution 측면에서는 제한이 있으며,
			각도 분해능angular resolution이 약 1° 정도로 떨어지며
			근접한 객체를 분리하는 데 한계가 있을 수 있음​
			
			센서가 서로 가까이 있는 두 물체를 구분할 수 있는
			최소한의 각도 간격이 1도 정도라는 뜻
			
			레이더 센서가 두 물체를 ‘서로 다른 대상’으로 인식하려면,
			그 물체들이 1도 이상 떨어져 있어야 함
			만약 두 물체가 0.5도 차이로 아주 가까이 있다면,
			센서는 그걸 하나의 물체로 착각하거나 정확히 구분하지 못할 수 있음

라이다 Lidar
	LIght
	Detection
	And
	Ranging
	라이다 정리
	라이다 필기정리
	
	레이저광(=주로 적외선 파장대)을 사용하여 주변 환경의 3차원 정보를 획득하는 센서
	
	고속으로 펄스 형태의 레이저 빔을 발사하고,
	물체에 반사되어 돌아오는 빛의 왕복 시간을 측정함으로써
	거리 정보를 얻음
	
	레이더와 똑같이 TOF(Time of Flight) 원리에 기반하지만 전파대신 광파를 사용함
	수 센티미터 이내의 정밀도로 목표물까지의 거리를 계산함
	
	포인트 클라우드(point cloud)
		수많은 점(point)들이 3차원 공간 상의 좌표(x, y, z)를 가지고 모여 있는 데이터 구조
	
	3차원 지도
		포인트클라우드 + 의미 있는 해석/가공
		
		포인트 클라우드 제공은 LiDAR의 기능
		해석/가공은 소프트웨어의 기능
	
	사용 전자기 스펙트럼 - 광파
	
	레이저의 {파장=짧음, 주파수=높음}
		작은 물체나 세밀한 지형 특징까지도 감지가능
		높은 해상도의 3D 포인트 클라우드를 생성가능
		
		일반적인 차량용 LiDAR의 사용 파장
			905nm / 1550nm대의 레이저를 이용
			비용/효율/안전성 등을 고려해서 2중 하나를 사용
			
			2가지 파장의 특징
				905nm
					부품이 저렴하고, 제조 공정이 성숙함
					표준 CMOS 센서로 수광이 가능 => 기존 카메라 기술과 쉽게 통합 가능
					단점: 인체 눈에 해로울 수 있어서 출력 제한 필요
						눈 안전 규제(IEC 60825)를 준수해야 함
					소형화에 유리함
					OEM 차량 디자인(그릴, 범퍼, 루프라인)에 잘 통합됨
					Valeo SCALA 2, InnovizOne, Ibeo NEXT 등 양산차용 LiDAR 대부분이 905nm를 사용
				
				1550nm
					인체의 눈에는 거의 흡수되지 않아 더 높은 출력 사용 가능
					더 긴 거리 탐지에 유리
					단점: 광원과 검출기 부품이 비싸고, 열에 민감함
					열민감성
						차량 탑재 환경은 여름철 햇빛 아래에서 60~85°C까지 내부 온도가 상승할 수 있음
						
						검출기 (수광 센서) 재질의 특성
							25°C => 65°C로 올라가면
							신호 대 잡음비(SNR)가 50% 이상 저하될 수 있음
						광원(레이저 다이오드)의 온도 안정성
							1550nm용 DFB 레이저 다이오드나 펄스 파장 레이저는 일반적으로 출력 강도와 파장이 온도에 민감
							보통 레이저 출력은 1°C 상승할 때 0.5~1% 감소, 파장도 수 나노미터씩 드리프트(shift)가 발생
							그래서 정확한 거리 측정을 위해선 **온도 보정 회로 또는 TEC(열전냉각기)가 필요
	
	
	센서 아키텍처
		{레이저 발진기, 빔 조향 장치, 광수신기, 신호처리부}
		
		레이저 발진기
			Laser Emitter
			레이저 펄스 생성
			905nm or 1550nm 파장대의 고출력 단일파장 레이저 사용
			주기적으로 고속 펄스를 생성하여 거리 측정의 시간 기준 신호 제공
			출력 안정성과 온도 특성에 따라 LiDAR 성능이 크게 좌우됨
			
			구성 부품 = {LD + 드라이버 회로}
				LD = 전구,
				드라이버 회로 = 전등 스위치 + 디밍 조절기
				
				LD
					Laser Diode
					반도체 기반 레이저 발진기
					좁은 파장대의 레이저 빛을 생성
					DFB구조를 사용해 안정적인 단일파장 유지
						Distributed Feedback
				
				드라이버 회로
					LD에 전류를 인가하여 펄스 출력 제어
					출력 전력, 펄스 반복률, 듀티사이클 조절
		
		빔 조향 장치
			Beam Steering mechanism
			스캐닝 장치를 이용하여 주변 공간을 빠르게 쓸면서 다각도로 빛을 투사
			
			LD에서 생성된 펄스를 좁은 빔으로 정렬(optics)하고,
			공간을 스캔하도록 방향을 제어(steering)하는 역할
			
			스캐닝 장치
				물리적 구조가 아닌, 광선의 조준 및 조사 방향을 실현하는 기술 요소들을 묶은 개념
				
				렌즈나 반사경 = 출사되는 빔을 한 점에 집중
				MEMS 미러 등 = 그 빔을 다방향으로 회전/조향
			
			구성 방식
				아래 기술들 중 하나 또는 조합
				
				회전식 스캐너 (기계식)
				MEMS 미러 (전자식)
				OPA (전자식, 고정형)
		
		광수신기Photodetector
			환경에서 반사되어 돌아온 레이저는 수신 광학계를 통해 광검출기에 집속되어 전기신호로 변환됨
			
			광검출기 종류
				APD
					Avalanche Photodiode
					광다이오드
					반사광 감지
					증폭 기능 있는 광다이오임
					약한 신호를 감지함
					단점: 노이즈가 크고, 온도에 민감
					자동차용 중~고성능 LiDAR에 사용됨
				
				SiPM
					Silicon Photomultiplier
					광다이오드
					고감도 광감지
					APD보다 고성능, 비싸고 회로 복잡함
					초미세 빛도 감지
					노이즈에 강하고 정확한 시간 측정에 유리
					고정밀 LiDAR, ToF 카메라, 양자광학 분야 등에 사용됨
		
		신호처리부
			포인트 클라우드 생성
			위의 신호는 극히 짧은 펄스의 시간차를 정밀 측정할 수 있는 TDC or ADC를 통해 디지털화됨
			
			TDC
				Time to Digital Converter
				빛이 반사되어 돌아온 시간 차이를 디지털 신호로 정밀하게 변환하는 장치
				TOF 기반 거리 계산용
					Time of Flight
					빛(또는 전파)을 쏘고, 물체에 반사되어 돌아오는 데 걸린 시간
				매우 정밀
				펄스 기반 LiDAR에서 사용됨
			
			ADC
				Analog to Digital Converter
				빛의 강도 등 아날로그 신호 처리
				APD나 SiPM이 만든 전기 신호(아날로그 전압)를 디지털 값으로 바꿔주는 장치

SVM
	서포트 벡터 머신
	Support Vector Machine
	svm 정리
	svm 필기정리
	
	용어	설명
		
		지도 학습
			Supervised Learning
			정답을 알려주고 배우는 방식
			예: 사진에 '고양이'라고 알려주면, 이후에 고양이 사진을 잘 구분하도록 학습함
		
		분류 알고리즘
			Classification Algorithm
			무언가를 그룹으로 나누는 규칙 (예: 고양이냐 강아지냐, 스팸이냐 아니냐)
			가장 유명한 알고리즘 중 하나가 SVM
		특징공간
			feature space
			데이터를 나타내는 여러 가지 특성(=특징)을 좌표축으로 삼아 펼쳐 놓은 추상적 공간
			
			사람을 분류할 때 키, 몸무게, 나이 같은 항목을 각각 축으로 사용하면,
				각 사람은 이 축위의 (키, 몸무게, 나이) 좌표값 한 점이 됨
				이렇게 여러 가지 특성(특징)을 좌표로 두고,
				각 데이터 포인트를 해당 좌표값으로 표현해 배치한 공간을 특징공간이라고 부름
				여기서 SVM은 이 공간에서 데이터들의 분포 형태를 보고, 최적의 분류 경계를 찾음
		
		고차원 특징 공간
			High-dimensional Feature Space
			비교할 정보가 엄청 많은 상황
			컴퓨터가 이미지를 볼 때는 픽셀 하나하나를 숫자로 바꿔서 비교함
			100×100 사진은 픽셀이 10,000개 => 10,000차원의 공간에서 비교하는 것과 같음
			이런 상황을 "고차원 공간에서 데이터를 분류한다"고 표현함
			차원이 높을수록 계산은 복잡하지만, 더 정밀한 판단이 가능
		
		분류 성능
			Classification Performance
			얼마나 잘 구분하느냐 = 맞춘 비율/실수한 횟수/등등
			분류 알고리즘이 얼마나 잘 작동하느냐를 평가하는 지표
			전체 100개 중 95개를 맞췄다면, 정확도는 95%
			정밀도(precision), 재현율(recall), F1-score 같은 여러 지표가 있음
		
		과적합
			Overfitting
			학습할 때 너무 정답에 맞추려고 해서,
			훈련 데이터만 잘 맞고, 실제 상황에선 틀리는 현상
			이걸 피하려면, 일반화가 잘 되도록 학습해야 함
		
		최대 마진 특성
			Maximum Margin Property
			SVM에서 나온 개념
			두 그룹을 구분할 때, 서로 최대한 떨어지게 경계를 그음
			그래야 나중에 새로운 데이터가 들어와도 안전하게 구분할 수 있기 때문
			중립 구역을 넓게 확보해놓고, 실수할 확률을 줄이는 전략
			
			마진
				각 그룹에서 가장 경계선과 가까운 점(즉, 가장 바깥쪽에 있는 점)부터
				경계선까지의 거리를 뜻함
				
				이 거리를 양쪽 그룹 모두에서 측정하니,
				양쪽 다 합쳐서 전체 마진이라고 부르기도 함
	
	
	지도학습 기반의 분류 알고리즘
		고차원 특징 공간에서도 안정적인 분류 성능을 보이고,
		과적합을 효과적으로 방지하는 최대 마진 특성을 가짐
		
		이러한 장점 때문에 딥러닝이 본격적으로 도입되기 전부터,
		한정된 데이터로도 높은 성능을 내야 했던 자동차 센서 응용 분야에서 SVM이 적극 활용됨
	
	포인트 클라우드 데이터로부터 물체나 사람을 구분하기 위해서는
		효과적인 분류 알고리즘이 필요함
	
	이러한 분류 작업에 널리 사용되는 지도학습 알고리즘 중 하나임
	
	사전에 레이블된 학습 데이터를 사용하여 모델을 학습하며,
		새로운 데이터 포인트가 주어졌을 때 그 포인트의 클래스를 예측함​
	
	
	SVM의 분류 원리는 초평면을 활용한 선형 분류에 있음
		
		초평면
			hyperplane
			자료가 놓여 있는 공간에서 차원이 하나 낮은 부분 공간
			2차원 공간(평면)에서 차원이 하나 낮으면	=> 1차원=직선
			3차원 공간(입체)에서 차원이 하나 낮으면	=> 2차원=평면
			
			즉, 2D에서 경계가 되는 건 직선, 3D에서 경계가 되는 건 평면인데,
				이것을 더 일반화한 것이 n차원에서의 (n-1)차원 경계임
			
			초평면 = (n-1)차원 경계
			
			SVM에서 이 초평면이 분류를 위한 결정 경계가 됨
				10차원 특징 공간이라면 9차원짜리 초평면이 데이터들을 둘로 나누는 기준선 역할을 하게 되는 것
		
		특징 공간에서 데이터 포인트들이 두 클래스로 나뉘어 있을 때,
			SVM은 이 둘을 갈라놓는 하나의 평면=초평면을 찾음
		
		이러한 초평면은 방정식으로 표현되며,
		SVM 모델은 학습을 통해 최적의 초평면 파라미터를 산출함
			파라미터 = 가중치 벡터 w와 절편 b
		
		새로운 데이터 포인트 x에 대해
		함수 f(x) = w⋅x + b
		의 부호(sign)를 보고
		한쪽이면 클래스 A, 반대쪽이면 클래스 B로 분류함
		
		f(x) = w1​⋅x1 + w2​⋅x2 + ... +wn​⋅xn​ + b
			를 계산했을 때 값이 양수면 클래스 A, 음수면 클래스 B에 속한다고 보는 방식
		
		위 식이 "1차 방정식"인 것과, "초평면이 (n−1)차원"인 건 다른 개념임
			100×100 픽셀의 이미지를 한 점으로 표현하면, 그 특징 벡터(데이터)는 10,000차원 공간에 놓이게 됨
			이 10,000차원 공간에서 하나의 1차 방정식(w⋅x + b = 0)은 (10,000−1)차원의 초평면을 정의함
			위의 1차 방정식은 "각 항인 x에 대한 차수가 1이다"라는 의미이지, 공간의 차원이 1이라는 뜻이 아님
			
			2차원 평면 위에서 w₁x₁ + w₂x₂ + b = 0은 직선을 나타냄 → 직선은 1차원
			3차원 공간에서 w₁x₁ + w₂x₂ + w₃x₃ + b = 0은 평면을 나타냄 → 평면은 2차원
			10,000차원 공간에서 w₁x₁ + … + w_₁₀₀₀₀x₁₀₀₀₀ + b = 0은 (9999)차원 초평면을 나타냄.
		
		훈련용 데이터셋을 기준으로 보면, 두 클래스를 구분하는 다양한 초평면 후보가 존재할 수 있음
		SVM은 이 학습 데이터 상에서 가장 넓은 여유(margin)를 확보하는 초평면을 최적해로 선택함
			실제로 SVM을 학습시킬 때는 훈련 예제들이 주어져 있음
				예: X라는 클래스에 속하는 점들, Y라는 클래스에 속하는 점들
			훈련용 데이터가 배치된 공간을 보고, 두 클래스를 나누는 "다양한 초평면들"을 생각해볼 수 있다는 뜻
		
		마진
			초평면과 각각의 클래스에 속한 데이터 점들 사이의 최소 거리
			SVM은 양 클래스의 데이터에 가장 가까운 점들로부터 최대 거리를 두는 초평면을 찾는 것
		
		서포트 벡터
			support vector
			초평면에 가장 근접하게 위치하여 분류 경계를 결정짓는 일부 데이터 점들
			서포트 벡터는 말 그대로 초평면을 지지하는 역할을 하며,
			이 점들이 초평면의 위치를 결정함
			다른 학습 점들은 이 경계에서 멀리 떨어져 있다면 모델에 큰 영향을 주지 않음
		
		그림설명
			대충 그 그림
			
			각각의 선(H1, H2, H3)은 가능한 분류 경계(초평면) 후보를 나타냄.
				훈련용 데이터가 2차원 평면에 있다고 가정하면,
				H1: 두 클래스를 제대로 분리 못함(한쪽 클래스의 일부 점이 반대편에 섞여 있음)
				H2: 두 클래스를 분리하긴 하지만, 두 클래스와 선 사이의 여유(마진)가 좁음
				H3: 두 클래스를 정확히 분리하면서, 양쪽 데이터와 경계선 간 거리가 가장 넓음 => 최대 마진
		
		일반화
			generalization
			훈련 데이터 외에 새로운 데이터가 들어왔을 때도 모델이 얼마나 잘 맞출 수 있는가를 의미
		
		SVM은 최대 마진을 확보하는 경계를 찾음으로써 일반화 성능을 높이고자 함
		
		마진이 넓을수록 두 클래스 데이터와 경계 사이에 충분한 완충 여유가 생기므로,
		약간의 데이터 변동이나 노이즈가 있어도 잘못 분류될 확률이 줄어듦
		
		실제로 마진을 크게 설정하면 모델의 일반화 오류generalization error가 낮아지는 경향이 있으며,
		이는 곧 과적합overfitting 위험을 줄여줌을 의미함
		
		SVM이 최대 마진을 추구하는 것은
			단순히 훈련 데이터만 잘 맞추는 것이 아니라
			새로운 데이터에도 잘 맞는 결정 경계를 얻기 위한 것임
			
			여기서 말하는 결정경계란 가장 마진이 넓은 n-1차원이라는 뜻
		
		이러한 원리 덕분에 SVM 모델은 노이즈나 이상치Outlier에도 비교적 견고한 것으로 알려져 있으며,
		일부 잘못 분류된 예제가 있어도 경계에 큰 영향을 주지 않도록 설계됨
		
		완벽하게 선형 분리가 불가능한 경우에는 소프트 마진 기법을 사용
			약간의 오류를 허용하면서 최대 마진을 찾는데,
				이는 일정 수준의 분류 오류를 허용해,
				복잡한 모델이 되는 것을 막는 규제효과를 가짐
	
	SVM의 학습 알고리즘과 과적합 방지
		SVM 모델을 학습시키는 과정은 최적화 기반의 알고리즘으로 이루어짐
		
		여기서 모델의 의미
			학습 과정을 거쳐 나온 최종 결정 경계(초평면)와 그 파라미터(w, b) 전체
			새로운 데이터 x에 대해 f(x)=w⋅x+b 값을 계산해 클래스 A/B를 판별하게 되는 분류기(classifier) 자체
		
		여기서 최적화의 의미
			optimization
			최적(가장 좋은) 해를 수학적으로 찾아가는 과정을 뜻함
			
			SVM의 경우,
				두 클래스를 분리하는 초평면 중에서
					마진(margin)을 최대화하고, 필요하다면 분류 오류(소프트 마진)를 최소화하는
					목적 함수를 최대/최소화하는 수학적 문제를 풀어야 함
					
					이것이 최적화 문제이고,
					학습 알고리즘은 이 최적화 문제를 효율적으로 풀어서
					초평면 파라미터(w, b)를 구하는 과정으로 볼 수 있음.
		
		용어정리
			노름(norm)
				벡터의 길이를 나타내는 수학적 값
			
			볼록(convex) 최적화
				목적함수나 제약이 "볼"록(convex)한 형태라서,
				아무 지역해도 곧 전역 최적해가 되는 문제
				를 푸는 최적화임
				
				SVM의 마진 최대화는 볼록 최적화 문제로 만들 수 있기에,
				해가 유일하고 안정적임.
			
			정식화
				formulation
				수학적 모델링
				현실 문제를 수학적 식으로 바꿔 표현하는 과정
			
			목적함수
				objective function
				최소화 혹은 최대화하고 싶은 수학식
				예
					오류율을 최소화하거나,
					마진을 최대화하거나
					하는 식이 목적함수가 됨
			
			이차 형태의 목적함수
				변수들이 제곱(또는 변수끼리 곱)으로 등장하는 형태의 식
			
			선형 제약
				linear constraint
				ax+by≤c처럼 1차 형태로 쓰인 제한 조건
				고차항(제곱, 곱)이 아닌 1차 항만 있는 식 = 선형 제약
			
			이차 계획법
				quadratic programming
				{이차 형태의 목적함수 + 선형 제약}이 주어진 문제를 푸는 방식
				SVM은 마진 최대화 식을 이 형태로 바꾼 뒤,
				전용 QP 솔버(알고리즘)로 최적 해를 구함
			
			QP 알고리즘
				이차 계획법을 효율적으로 푸는 알고리즘
				예
					SMO(Sequential Minimal Optimization),
					내부점법,
					단순히 “QP 솔버”
					등등 여러 방안이 있음.
			
			라그랑주 승수법
				Lagrange multiplier
				제약이 있는 최적화 문제에서, "라그랑주 승수"라는
				새로운 변수를 도입해 문제를 푸는 수학적 기법
				제약 조건을 목적함수에 합쳐 풀어가는 방식임
			
			쿤터커 조건
				KKT 조건
				라그랑주 승수법 같은 최적화 문제에서 해가 되기 위한 필수 조건
				미분 가능성, 제약 만족, 승수의 부호 등
			
			손실
				loss
				모델이 내린 예측이 정답과 어느 정도 틀렸는지를 수치화한 것
				예
					오분류된 샘플 수,
					혹은 예측값과 실제값 차이의 제곱합,
					등등
			
			손실 최소화
				모델의 오차나 틀림 정도를 가능한 작게 만들도록 하는 것
				딥러닝, SVM 등 머신러닝 전반에서 중요한 목표
			
			모델 복잡도
				model complexity
				모델이 갖는 파라미터 수나, 계산 구조의 복잡성 등을 뜻함
				너무 복잡하면 훈련 데이터에는 잘 맞지만,
				새 데이터에서 오차가 커지는 과적합 위험이 큼
			
			구조적 위험
				structural risk
				{훈련 데이터에 대한 오차 + 모델 복잡도}가 함께 고려된 "전체 위험"
				즉, "과적합 여부"까지 아우르는 위험이라 볼 수 있음
			
			구조적 위험 최소화
				SRM
				단순히 손실(훈련 오차)만 최소화하는 게 아니라,
				모델 복잡도도 함께 줄이려는 학습 이론
				훈련에 잘 맞추되, 새 데이터에도 잘 맞출 수 있도록
				모델이 "너무 복잡해지지 않게" 제어함.
			
			제약 조건
				모든 데이터가 올바르게 분류된다는 조건
		
		학습을 진행하며 SVM은 주어진 훈련 데이터에 대해 마진이 최대가 되는 초평면의 파라미터 (w, b)를 찾아냄
		
		이는 수학적으로 제약 조건 하에서 마진을 극대화(또는 w의 노름을 최소화)하는 볼록(convex) 최적화 문제로 정식화
		
		SVM의 이러한 최적화 문제는 이차형태의 목적함수와 선형제약으로 이루어진 이차 계획법 문제로 변환되며,
		전용 QP 알고리즘을 통해 해를 구할 수 있음​
		
		이 과정에서 라그랑주 승수법과 쿤터커 조건 등의 수학적 원리가 활용되어, 최적의 해를 효율적으로 찾게 됨
		
		핵심은 SVM 학습이 손실 최소화와 모델 복잡도 최소화를 동시에 달성하도록 설정된다는 점임
		이런 설정은 통계적 학습이론의 구조적 위험 최소화 개념과 맥락을 같이하여,
		단순히 훈련 데이터에 정확히 맞추는 것뿐 아니라,
		모델의 복잡도를 적절히 억제함으로써,
		일반화 능력을 높이는 효과가 있음
		
		학습이 완료되면
			SVM 모델 = 지원 벡터(서포트 벡터)들의 정보
	
	용어 정리
		마진 경계
			Margin Boundary
			SVM에서 서포트 벡터가 위치하는 지점 주변으로,
			두 클래스를 구분하는 초평면(결정 경계)와
			평행하게 형성되는 경계
			
			쉽게 말해, 이 선(혹은 면) 안쪽으로는
			더 이상 데이터 점이 들어오면 안 된다는
			임계선 역할
			
			2차원 예시에서,
				결정 경계(한 줄)
				양옆에 나란히 있는 두 줄
				이게 마진 경계임
			
			가중치, 가중치 값
				SVM에서 학습이 끝나면, w라는 벡터와 b라는 절편이 결정됨.
				w는 각 특징에 곱해지는 비중(가중)들을 모아둔 것
				
				SVM의 최적화 해(라그랑주 승수)와 직결되며,
				서포트 벡터의 기여만으로 w가 정해짐
			
			가중치 값(라그랑주 승수와 대응)
				서포트 벡터로 판정된 데이터 포인트만이
				"알파(α_i) ≠ 0"인 상태로 남음
				
				이 값(α_i)이 0이 아닌 포인트들만이,
				실제로 결정 경계를 만드는 데 참여함
				
				알파(α_i)는 곧바로 w 자체가 아님
				w는
					𝑤 = ∑𝑖∈SV 𝛼𝑖*𝑦𝑖*𝑥𝑖 형태로,
					알파(α)와 레이블(y_i), 그리고 해당 데이터의 벡터(x_i)를 합산한 결과임
				즉,
					알파는 w를 구성하는 요소이긴 하지만,
					그 자체가 w는 아님.
			
			최종 결정 경계
				Final Decision Boundary
				SVM이 학습을 마친 뒤 새로 들어온 데이터를 분류할 때 사용하는 초평면
	
	최적화 결과로 마진 경계에 위치한 서포트 벡터는 가중치 값이 0이 아닌 상태로 남게 되고, 이 벡터들만이 최종 결정 경계를 형성하는 데 기여함
		
		그 외의 데이터 포인트는 경계에서 여유가 있어 가중치 값이 0이므로,
		분류 결정식에 직접 등장하지 않음
		
		이렇게 모델이 "일부 핵심 데이터 포인트"에 의해 결정되도록 함으로써,
		SVM은 불필요하게 복잡한 결정 경계를 방지하고 과적합을 피하는 성질을 보임​
		
		훈련된 SVM 모델로 예측을 수행할 때는,
		새로운 입력의 특징 벡터와 학습된 모델의 서포트 벡터들 간의 내적연산을 통해 결정 함수 f(x) 값을 계산하고 부호를 판별함
		이러한 계산은 비교적 간단한 선형 연산으로 이루어짐
	
	
	SVM을 통해 LiDAR 로 얻은 데이터에서 물체 분류나 사람 인식이 가능함
		
		용어정리
			클러스터
				cluster
				데이터 포인트들 중 서로 유사한 것들끼리 묶음을 형성한 것
				예를 들어 차량 내부 포인트클라우드에서
				{좌석 영역, 바닥 영역, 사람} 등으로 모여 있는 점들의 집합의
				각각을 클러스터라고 함
			점군
				흔히 포인트클라우드라고 부르는,
				(x, y, z) 좌표로 이루어진 다수의 점 집합
				LiDAR가 스캔하여 획득한 3D 좌표들이 이에 해당함
		
		차량 내부에 설치된 LiDAR는 좌석 위나 주변의 3차원 점군 데이터를 획득함
		
		이 데이터를 처리하여 개별 객체에 해당하는 클러스터를 분리하거나,
		관심 영역의 점군에 대해 특징을 산출함.
		이러한 특징은 예를 들어 {물체의 크기, 형상 분포, 밀도, 높이} 등으로 표현될 수 있음
		사람몸체에 해당하는 점군과 크기/모양과 다르면
		그 물체(가방, 박스 등)의 점군 특징은 다르게 나타남

